ğŸ§  Prep-Brain

A calm, local kitchen brain built for real service.

Prep-Brain is a local, voice-first restaurant assistant that helps you think, remember, and act under real kitchen conditions â€” not demos, not hype, not â€œAI for vibes.â€

You talk to it through Telegram.
It listens, remembers context, reasons with your documents, and answers clearly.

Think of it as:

a senior operations brain that knows your restaurants, your systems, and your constraints â€” and stays quiet when it should.

â¸»

What Prep-Brain Is (and Is Not)

Prep-Brain is:
	â€¢	Local-first (your data stays on your machine)
	â€¢	Voice-first (built for kitchens, not keyboards)
	â€¢	Context-aware (sessions + memory)
	â€¢	Document-grounded (RAG, not hallucination)
	â€¢	Inspectable and reversible

Prep-Brain is not:
	â€¢	A SaaS
	â€¢	A generic chatbot wrapper
	â€¢	A stateless demo
	â€¢	An â€œomniscientâ€ system with hidden memory

â¸»

Whatâ€™s Working Right Now

These features are implemented and functional.

Capability	Status	Location
Telegram text â†’ contextual AI reply	âœ… Working	services/bot.py + services/brain.py
Voice notes â†’ transcription â†’ AI reply	âœ… Working	services/bot.py + services/transcriber.py
Persistent memory (users / sessions / messages)	âœ… Working	services/memory.py
RAG ingestion + retrieval with source controls	âœ… Working	services/rag.py
Telegram document upload â†’ knowledge ingestion	âœ… Working	services/bot.py
Local dashboard for control & inspection	âœ… Working	dashboard/app.py


â¸»

What the Dashboard Can Do
	â€¢	Start / stop / restart the bot
	â€¢	Check Ollama status
	â€¢	View live logs
	â€¢	Inspect and clear session history
	â€¢	Upload and manage knowledge sources
	â€¢	Enable / disable / remove RAG sources
	â€¢	Edit config and system prompt live (no restarts)

The dashboard exists for trust and control, not decoration.

â¸»

Knowledge & RAG (How It Actually Works)

Prep-Brain uses a Retrieval-Augmented Generation (RAG) system to reason over your documents.

You can ingest:
	â€¢	PDFs
	â€¢	SOPs
	â€¢	prep bibles
	â€¢	recipes
	â€¢	station notes
	â€¢	menus
	â€¢	vendor sheets
	â€¢	post-service notes

Each source is:
	â€¢	indexed
	â€¢	embedded
	â€¢	stored with metadata
	â€¢	individually controllable (active / disabled / removed)

Important:
	â€¢	The assistant does not blindly â€œlearnâ€ documents.
	â€¢	It retrieves relevant sections and reasons over them at runtime.
	â€¢	Sources are always inspectable and reversible.
	â€¢	Web research (if enabled) is contextual and not auto-saved.

This allows per-restaurant / per-project knowledge separation, so answers stay grounded in the correct venue context.

â¸»

Tech Stack (Chosen on Purpose)
	â€¢	Python
	â€¢	python-telegram-bot
	â€¢	Ollama (local LLM backend)
	â€¢	ChromaDB + sentence-transformers (RAG)
	â€¢	Streamlit (dashboard)
	â€¢	SQLite (memory)
	â€¢	ffmpeg + whisper-cli (audio transcription)

Boring. Replaceable. Reliable.

â¸»

Project Layout

prep-brain/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ bot.py           # Telegram handlers (text, voice, documents)
â”‚   â”œâ”€â”€ brain.py         # Ollama client + RAG context injection
â”‚   â”œâ”€â”€ memory.py        # SQLite session & message memory
â”‚   â”œâ”€â”€ rag.py           # Ingestion + retrieval engine
â”‚   â””â”€â”€ transcriber.py   # whisper-cli wrapper
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ app.py           # Main Streamlit control panel
â”‚   â””â”€â”€ pages/           # Sessions, Test Lab, Settings, Knowledge
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ verify_rag.py
â”œâ”€â”€ config.yaml
â”œâ”€â”€ .env.example
â””â”€â”€ requirements.txt


â¸»

Quick Start

Prerequisites
	â€¢	Python 3.10+
	â€¢	ffmpeg in PATH
	â€¢	whisper-cli in PATH
	â€¢	Ollama installed locally

â¸»

1) Install dependencies

python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt


â¸»

2) Environment setup

cp .env.example .env

Set your Telegram bot token in .env.

â¸»

3) Configure the app

Edit config.yaml:
	â€¢	Ollama base URL & model
	â€¢	Optional Telegram allow-list
	â€¢	RAG enable/disable

All of this can also be edited live from the dashboard.

â¸»

4) Start Ollama

ollama serve

Pull a model if needed:

ollama pull llama3.1:8b


â¸»

5) Run the bot

source .venv/bin/activate
python -m services.bot


â¸»

6) Run the dashboard

streamlit run dashboard/app.py


â¸»

Message Flows (Implemented)
	â€¢	Text
	â€¢	Message â†’ session memory â†’ Ollama â†’ reply
	â€¢	Voice
	â€¢	Voice note â†’ ffmpeg â†’ whisper â†’ transcript
	â€¢	Transcript â†’ memory â†’ Ollama â†’ reply
	â€¢	Documents
	â€¢	Upload â†’ ingestion â†’ indexed knowledge source
	â€¢	Source can be enabled/disabled at any time

â¸»

Notes & Safety
	â€¢	Runtime data (data/, logs/, models/) is intentionally git-ignored
	â€¢	Mixed image/text PDFs require OCR before ingestion
	â€¢	RAG retrieval only uses sources marked active
	â€¢	Knowledge sources can always be removed

Nothing is hidden. Nothing is irreversible.

â¸»

Status

Prep-Brain is an active, evolving system.

Itâ€™s built for:
	â€¢	real kitchens
	â€¢	real constraints
	â€¢	real thinking under pressure

If youâ€™re looking for a chatbot demo, this isnâ€™t it.

If youâ€™re building a thinking tool for operations, welcome.